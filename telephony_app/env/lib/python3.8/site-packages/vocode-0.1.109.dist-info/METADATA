Metadata-Version: 2.1
Name: vocode
Version: 0.1.109
Summary: The all-in-one voice SDK
Home-page: https://github.com/vocodedev/vocode-python
License: MIT
Author: Ajay Raj
Author-email: ajay@vocode.dev
Requires-Python: >=3.8.1,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Provides-Extra: agents
Provides-Extra: all
Provides-Extra: synthesizers
Provides-Extra: telephony
Provides-Extra: transcribers
Requires-Dist: anthropic (>=0.2.7,<0.3.0) ; extra == "agents" or extra == "all"
Requires-Dist: azure-cognitiveservices-speech (>=1.27.0,<2.0.0)
Requires-Dist: elevenlabs (>=0.2.6,<0.3.0) ; extra == "synthesizers" or extra == "all"
Requires-Dist: fastapi (>=0.95.1,<0.96.0)
Requires-Dist: google-cloud-speech (>=2.19.0,<3.0.0) ; extra == "transcribers" or extra == "all"
Requires-Dist: google-cloud-texttospeech (>=2.14.1,<3.0.0) ; extra == "synthesizers" or extra == "all"
Requires-Dist: gtts (>=2.3.1,<3.0.0) ; extra == "synthesizers" or extra == "all"
Requires-Dist: janus (>=1.0.0,<2.0.0)
Requires-Dist: jinja2 (>=3.1.2,<4.0.0)
Requires-Dist: langchain (>=0.0.149,<0.0.150)
Requires-Dist: nltk (>=3.8.1,<4.0.0)
Requires-Dist: openai (>=0.27.4,<0.28.0)
Requires-Dist: opentelemetry-sdk (>=1.17.0,<2.0.0)
Requires-Dist: pydub (>=0.25.1,<0.26.0)
Requires-Dist: python-multipart (>=0.0.6,<0.0.7)
Requires-Dist: redis (>=4.5.4,<5.0.0) ; extra == "telephony" or extra == "all"
Requires-Dist: requests (>=2.28.2,<3.0.0)
Requires-Dist: six (>=1.16.0,<2.0.0)
Requires-Dist: sounddevice (>=0.4.6,<0.5.0)
Requires-Dist: twilio (>=8.1.0,<9.0.0) ; extra == "telephony" or extra == "all"
Requires-Dist: uvicorn (>=0.21.1,<0.22.0)
Requires-Dist: websockets (>=11.0.2,<12.0.0)
Description-Content-Type: text/markdown

<div align="center">

![Hero](https://user-images.githubusercontent.com/6234599/228337850-e32bb01d-3701-47ef-a433-3221c9e0e56e.png)

[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/vocodehq.svg?style=social&label=Follow%20%40vocodehq)](https://twitter.com/vocodehq) [![GitHub Repo stars](https://img.shields.io/github/stars/vocodedev/vocode-python?style=social)](https://github.com/vocodedev/vocode-python)
[![Downloads](https://static.pepy.tech/badge/vocode/month)](https://pepy.tech/project/vocode)

[Community](https://discord.gg/NaU4mMgcnC) | [Docs](https://docs.vocode.dev) | [Dashboard](https://app.vocode.dev)

</div>

# <span><img style='vertical-align:middle; display:inline;' src="https://user-images.githubusercontent.com/6234599/228339858-95a0873a-2d40-4542-963a-6358d19086f5.svg"  width="5%" height="5%">&nbsp; vocode</span>

### **Build voice-based LLM apps in minutes**

Vocode is an open source library that makes it easy to build voice-based LLM apps. Using Vocode, you can build real-time streaming conversations with LLMs and deploy them to phone calls, Zoom meetings, and more. You can also build personal assistants or apps like voice-based chess. Vocode provides easy abstractions and integrations so that everything you need is in a single library.

We're actively looking for community maintainers, so please reach out if interested!

# ‚≠êÔ∏è Features

- üó£ [Spin up a conversation with your system audio](https://docs.vocode.dev/python-quickstart)
- ‚û°Ô∏è üìû [Set up a phone number that responds with a LLM-based agent](https://docs.vocode.dev/telephony#inbound-calls)
- üìû ‚û°Ô∏è [Send out phone calls from your phone number managed by an LLM-based agent](https://docs.vocode.dev/telephony#outbound-calls)
- üßë‚Äçüíª [Dial into a Zoom call](https://github.com/vocodedev/vocode-python/blob/main/vocode/streaming/telephony/hosted/zoom_dial_in.py)
- Out of the box integrations with:
  - Transcription services, including:
    - [Deepgram](https://deepgram.com/)
    - [AssemblyAI](https://www.assemblyai.com/)
    - [Google Cloud](https://cloud.google.com/speech-to-text)
    - [Whisper](https://openai.com/blog/introducing-chatgpt-and-whisper-apis)
    - [RevAI](https://www.rev.ai/)
  - LLMs, including:
    - [ChatGPT](https://openai.com/blog/chatgpt)
    - [GPT-4](https://platform.openai.com/docs/models/gpt-4)
    - [Anthropic](https://www.anthropic.com/) - coming soon!
  - Synthesis services, including:
    - [Rime.ai](https://rime.ai)
    - [Microsoft Azure](https://azure.microsoft.com/en-us/products/cognitive-services/text-to-speech/)
    - [Google Cloud](https://cloud.google.com/text-to-speech)
    - [Play.ht](https://play.ht)
    - [Eleven Labs](https://elevenlabs.io/)
    - [Coqui](https://coqui.ai/)

Check out our React SDK [here](https://github.com/vocodedev/vocode-react-sdk)!

# ü´Ç Contribution

We're an open source project and are extremely open to contributors adding new features, integrations, and documentation! Please don't hesitate to reach out and get started building with us.

For more information on contributing, see our [Contribution Guide](https://github.com/vocodedev/vocode-python/blob/main/contributing.md).

And we'd love to talk to you on [Discord](https://discord.gg/NaU4mMgcnC)!

# üöÄ Quickstart (Self-hosted)

```bash
pip install 'vocode[io]'
```

```python
import asyncio
import signal

import vocode
from vocode.streaming.streaming_conversation import StreamingConversation
from vocode.helpers import create_microphone_input_and_speaker_output
from vocode.streaming.models.transcriber import (
    DeepgramTranscriberConfig,
    PunctuationEndpointingConfig,
)
from vocode.streaming.agent.chat_gpt_agent import ChatGPTAgent
from vocode.streaming.models.agent import ChatGPTAgentConfig
from vocode.streaming.models.message import BaseMessage
from vocode.streaming.models.synthesizer import AzureSynthesizerConfig
from vocode.streaming.synthesizer.azure_synthesizer import AzureSynthesizer
from vocode.streaming.transcriber.deepgram_transcriber import DeepgramTranscriber

# these can also be set as environment variables
vocode.setenv(
    OPENAI_API_KEY="<your OpenAI key>",
    DEEPGRAM_API_KEY="<your Deepgram key>",
    AZURE_SPEECH_KEY="<your Azure key>",
    AZURE_SPEECH_REGION="<your Azure region>",
)


async def main():
    microphone_input, speaker_output = create_microphone_input_and_speaker_output(
        streaming=True, use_default_devices=False
    )

    conversation = StreamingConversation(
        output_device=speaker_output,
        transcriber=DeepgramTranscriber(
            DeepgramTranscriberConfig.from_input_device(
                microphone_input, endpointing_config=PunctuationEndpointingConfig()
            )
        ),
        agent=ChatGPTAgent(
            ChatGPTAgentConfig(
                initial_message=BaseMessage(text="Hello!"),
                prompt_preamble="Have a pleasant conversation about life",
            ),
        ),
        synthesizer=AzureSynthesizer(
            AzureSynthesizerConfig.from_output_device(speaker_output)
        ),
    )
    await conversation.start()
    print("Conversation started, press Ctrl+C to end")
    signal.signal(signal.SIGINT, lambda _0, _1: conversation.terminate())
    while conversation.is_active():
        chunk = microphone_input.get_audio()
        if chunk:
            conversation.receive_audio(chunk)
        await asyncio.sleep(0)


if __name__ == "__main__":
    asyncio.run(main())
```

# ‚òÅÔ∏è Quickstart (Hosted)

First, get a _free_ API key from our [dashboard](https://app.vocode.dev).

```bash
pip install 'vocode[io]'
```

```python
import asyncio
import signal

import vocode
from vocode.streaming.hosted_streaming_conversation import HostedStreamingConversation
from vocode.streaming.streaming_conversation import StreamingConversation
from vocode.helpers import create_microphone_input_and_speaker_output
from vocode.streaming.models.transcriber import (
    DeepgramTranscriberConfig,
    PunctuationEndpointingConfig,
)
from vocode.streaming.models.agent import ChatGPTAgentConfig
from vocode.streaming.models.message import BaseMessage
from vocode.streaming.models.synthesizer import AzureSynthesizerConfig

vocode.api_key = "<your API key>"


if __name__ == "__main__":
    microphone_input, speaker_output = create_microphone_input_and_speaker_output(
        streaming=True, use_default_devices=False
    )

    conversation = HostedStreamingConversation(
        input_device=microphone_input,
        output_device=speaker_output,
        transcriber_config=DeepgramTranscriberConfig.from_input_device(
            microphone_input,
            endpointing_config=PunctuationEndpointingConfig(),
        ),
        agent_config=ChatGPTAgentConfig(
            initial_message=BaseMessage(text="Hello!"),
            prompt_preamble="Have a pleasant conversation about life",
        ),
        synthesizer_config=AzureSynthesizerConfig.from_output_device(speaker_output),
    )
    signal.signal(signal.SIGINT, lambda _0, _1: conversation.deactivate())
    asyncio.run(conversation.start())
```

# üìû Phone call quickstarts

- [Inbound calls - Hosted](https://docs.vocode.dev/telephony#inbound-calls)
- [Outbound calls - Hosted](https://docs.vocode.dev/telephony#outbound-calls)
- [Telephony Server - Self-hosted](https://github.com/vocodedev/vocode-python/blob/main/examples/telephony_app.py)

# üå± Documentation

[docs.vocode.dev](https://docs.vocode.dev/)

